{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ§¬ Genomics Workshop â€” Google Colab\n",
    "\n",
    "Welcome! This notebook contains the **full workshop pipeline** that installs required tools, clones the workshop repository, downloads example data, runs QC, trimming, mapping, variant calling, filtering, and a simple PCA.\n",
    "\n",
    "**NOTE:** This installs several bioinformatics tools in the Colab environment. Installation may take 5â€“15 minutes depending on the step.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify Python version and working directory\n",
    "import sys, os\n",
    "print('Python:', sys.version)\n",
    "!pwd\n",
    "!ls -la\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Clone the workshop repository\n",
    "The repo will be cloned into the Colab environment so the notebook can reference scripts and example files hosted there.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the GitHub repository (your repo)\n",
    "!if [ -d Genomics_learning_workshop ]; then echo 'Repo already exists'; else git clone https://github.com/PoODL-CES/Genomics_learning_workshop.git; fi\n",
    "!ls -la Genomics_learning_workshop | sed -n '1,120p'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Install system-level tools (BWA, samtools, bcftools, FastQC, Trim Galore, PLINK, Qualimap, Java for GATK)\n",
    "These commands use `apt-get` and `wget` to install commonly used tools. Some installations take a few minutes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update package lists\n",
    "!sudo apt-get update -qq\n",
    "# Install core bioinformatics tools\n",
    "!sudo apt-get install -y -qq bwa samtools bcftools \n",
    "# Install FastQC\n",
    "!sudo apt-get install -y -qq fastqc unzip\n",
    "# Install PLINK (plink1.9)\n",
    "!sudo apt-get install -y -qq plink\n",
    "# Install Qualimap dependencies (python3, pip) and java\n",
    "!sudo apt-get install -y -qq python3-pip default-jre\n",
    "# Install python packages used later\n",
    "!pip install --quiet pandas matplotlib seaborn\n",
    "# Report versions\n",
    "!bwa 2>&1 | head -n 1 || true\n",
    "!samtools --version | head -n 1 || true\n",
    "!bcftools --version | head -n 1 || true\n",
    "!fastqc --version || true\n",
    "!plink --version || true\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Trim Galore (script) and cutadapt\n",
    "Trim Galore is a wrapper (Python) around cutadapt. We'll download the Trim Galore script and install cutadapt via pip.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install cutadapt (required by Trim Galore)\n",
    "!pip install --quiet cutadapt\n",
    "# Download Trim Galore script (version-agnostic simple download)\n",
    "!wget -q https://raw.githubusercontent.com/FelixKrueger/TrimGalore/master/trim_galore\n",
    "!chmod +x trim_galore\n",
    "!./trim_galore --version || true\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install GATK (GenomeAnalysisTK)\n",
    "We'll download a pre-built GATK release and make it executable. This step downloads ~100MB+ and requires Java (installed above).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download GATK (example GATK4)\n",
    "!if [ -f gatk.zip ]; then echo 'GATK already downloaded'; else wget -q -O gatk.zip https://github.com/broadinstitute/gatk/releases/download/4.2.6.1/gatk-4.2.6.1.zip; fi\n",
    "!unzip -q -o gatk.zip -d /content/gatk || true\n",
    "!ls -la /content/gatk || true\n",
    "!java -jar /content/gatk/gatk-package-4.2.6.1-local.jar --help | head -n 5 || true\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Download example dataset (small subset)\n",
    "We'll download the example dataset from Zenodo. If you have a different link or files in the repo, you can modify these commands.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset directory and attempt download from Zenodo (example)\n",
    "!mkdir -p dataset\n",
    "%cd dataset\n",
    "# The Zenodo record page lists files; here we attempt to download a file named ngs_dataset.zip if available.\n",
    "!if [ -f ngs_dataset.zip ]; then echo 'dataset already present'; else wget -q https://zenodo.org/records/14258052/files/ngs_dataset.zip || echo 'download failed - please download manually and upload to /content/dataset/'; fi\n",
    "!if [ -f ngs_dataset.zip ]; then unzip -q -o ngs_dataset.zip; fi\n",
    "!ls -la | sed -n '1,200p'\n",
    "%cd ..\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) FastQC â€” Quality Check\n",
    "Run FastQC on FASTQ files found in `dataset/` (if any). The output will be written to `fastqc_reports/`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p fastqc_reports\n",
    "!fastqc -t 2 dataset/*.fastq.gz -o fastqc_reports || echo 'FastQC run skipped â€” no FASTQ found or error'\n",
    "!ls -la fastqc_reports || true\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Trim Galore â€” Adapter trimming\n",
    "This cell demonstrates paired-end trimming. Adjust filenames to match your downloaded dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example filenames (change as necessary)\n",
    "R1=$(ls dataset/*_R1*.fastq.gz 2>/dev/null | head -n1)\n",
    "R2=$(ls dataset/*_R2*.fastq.gz 2>/dev/null | head -n1)\n",
    "echo 'R1='${R1}\n",
    "echo 'R2='${R2}\n",
    "if [ -n \"$R1\" -a -n \"$R2\" ]; then mkdir -p trimmed_reads; ./trim_galore --paired $R1 $R2 -o trimmed_reads || echo 'TrimGalore failed'; else echo 'Paired FASTQ not found â€” skipping trimming'; fi\n",
    "!ls -la trimmed_reads || true\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Mapping with BWA, convert to BAM, sort, and index\n",
    "Ensure `reference/your_reference.fasta` exists in the repo or dataset; adjust path if necessary.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: detect reference in repo or dataset\n",
    "REF=$(ls Genomics_learning_workshop/reference/*.fasta 2>/dev/null | head -n1 || true)\n",
    "if [ -z \"$REF\" ]; then REF=$(ls dataset/*.fasta 2>/dev/null | head -n1 || true); fi\n",
    "echo 'Reference:' $REF\n",
    "# If reference found, index and map (on small example only)\n",
    "if [ -n \"$REF\" ]; then \n",
    "  bwa index $REF || echo 'bwa index failed'; \
    "  # pick trimmed reads if available otherwise raw\n",
    "  R1=$(ls trimmed_reads/*_val_1*.fq.gz 2>/dev/null | head -n1 || true); \
    "  R2=$(ls trimmed_reads/*_val_2*.fq.gz 2>/dev/null | head -n1 || true); \
    "  if [ -n \"$R1\" -a -n \"$R2\" ]; then \
    "     bwa mem -t 2 $REF $R1 $R2 > aln.sam || echo 'bwa mem failed'; \
    "  else \
    "     # try raw fastq\n",
    "     R1=$(ls dataset/*_R1*.fastq.gz 2>/dev/null | head -n1 || true); R2=$(ls dataset/*_R2*.fastq.gz 2>/dev/null | head -n1 || true); \
    "     if [ -n \"$R1\" -a -n \"$R2\" ]; then bwa mem -t 2 $REF $R1 $R2 > aln.sam || echo 'bwa mem failed'; else echo 'No paired reads found to map'; fi; \
    "  fi; \
    "  # Convert and sort\n",
    "  if [ -f aln.sam ]; then samtools view -bS aln.sam > aln.bam || true; samtools sort aln.bam -o aln.sorted.bam || true; samtools index aln.sorted.bam || true; fi\n",
    "else echo 'Reference not found â€” please upload reference fasta to Genomics_learning_workshop/reference/ or dataset/'; fi\n",
    "!ls -la *.bam *.sam || true\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7) Variant calling with bcftools (simple demo)\n",
    "If `aln.sorted.bam` exists and a reference is present, create a VCF. This is a minimal example for teaching purposes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if [ -f aln.sorted.bam -a -n \"$REF\" ]; then \n",
    "  bcftools mpileup -f $REF aln.sorted.bam -Ou | bcftools call -mv -Oz -o raw_variants.vcf.gz || echo 'bcftools call failed'; \n",
    "  bcftools index raw_variants.vcf.gz || true; \n",
    "  echo 'Generated raw_variants.vcf.gz'; \n",
    "else echo 'BAM or reference not present â€” skipping variant calling'; fi\n",
    "!ls -la raw_variants.vcf.gz* || true\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8) Basic VCF filtering\n",
    "Apply simple filters (depth, quality). Adjust thresholds for your data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if [ -f raw_variants.vcf.gz ]; then \n",
    "  bcftools filter -i 'DP>5 & QUAL>30' raw_variants.vcf.gz -Ov -o filtered_variants.vcf || echo 'Filtering failed'; \n",
    "  ls -lh filtered_variants.vcf || true; \n",
    "else echo 'No raw VCF to filter'; fi\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9) PCA: convert filtered VCF to PLINK and run PCA\n",
    "This step uses PLINK to convert and compute principal components. For multi-sample VCFs only.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if [ -f filtered_variants.vcf ]; then \n",
    "  plink --vcf filtered_variants.vcf --make-bed --out genotype_data || echo 'plink conversion failed'; \n",
    "  plink --bfile genotype_data --pca --out pca_results || echo 'plink pca failed'; \n",
    "  ls -la pca_results* || true; \n",
    "else echo 'filtered_variants.vcf not found â€” skipping PLINK steps'; fi\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10) Plot PCA (if available)\n",
    "Load the PLINK PCA output and plot PC1 vs PC2 using matplotlib.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, pandas as pd, matplotlib.pyplot as plt\n",
    "if os.path.exists('pca_results.eigenvec'):\n",
    "  df = pd.read_csv('pca_results.eigenvec', delim_whitespace=True, header=None)\n",
    "  # plink eigenvec format: FID IID PC1 PC2 ...\n",
    "  if df.shape[1] >= 4:\n",
    "    df_plot = df[[0,2,3]]\n",
    "    df_plot.columns = ['Sample','PC1','PC2']\n",
    "    plt.figure(figsize=(6,5))\n",
    "    plt.scatter(df_plot['PC1'], df_plot['PC2'])\n",
    "    plt.xlabel('PC1')\n",
    "    plt.ylabel('PC2')\n",
    "    plt.title('PCA (PC1 vs PC2)')\n",
    "    for i,row in df_plot.iterrows():\n",
    "      plt.text(row['PC1'], row['PC2'], str(row['Sample']), fontsize=8)\n",
    "    plt.show()\n",
    "  else:\n",
    "    print('PCA file has insufficient columns.')\n",
    "else:\n",
    "  print('pca_results.eigenvec not found â€” run PLINK PCA first')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Troubleshooting & Notes\n",
    "- Colab sessions are ephemeral. Save important outputs to Google Drive or download them.\n",
    "- Large genomes and high-depth datasets may not finish in Colab due to time or memory limits. Use small subsets for the workshop.\n",
    "- If a step fails, inspect the cell output and adjust file paths to match your dataset.\n",
    "\n",
    "### Quick commands to save results to Google Drive:\n",
    "```python\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "!cp filtered_variants.vcf /content/drive/MyDrive/\n",
    "```
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
