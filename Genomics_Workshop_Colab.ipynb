{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Genomics_Workshop.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aksinhaa/ColabFold/blob/main/Genomics_Workshop.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G4yBrceuFbf3"
      },
      "source": [
        "<video src=\"https://raw.githubusercontent.com/PoODL-CES/PoODL_NGS_workshop.io/main/Nature%20of%20Science.mp4\" controls autoplay loop width=\"400\" align=\"right\"></video>\n",
        "\n",
        "## Genomics Learning Workshop: NGS Analysis Pipeline\n",
        "\n",
        "Easy-to-follow workflow for processing Illumina whole-genome resequencing reads for population genomics. Steps include trimming, mapping, sorting, variant calling, variant filtering, PCA, and ADMIXTURE analysis. For more details, see the bottom of this notebook and visit the GitHub repository.\n",
        "Repository link: [Genomics Learning Workshop](https://github.com/PoODL-CES/Genomics_learning_workshop)\n",
        "\n",
        "This workshop introduces:\n",
        "- Handling raw FASTQ files\n",
        "- Performing quality control and trimming\n",
        "- Mapping reads to a reference genome\n",
        "- Calling and filtering variants\n",
        "- Running PCA and ADMIXTURE for population analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ee74ca19"
      },
      "source": [
        "#@title Install system-level NGS bioinformatics tools\n",
        "%%time\n",
        "\n",
        "# Install samtools, fastqc, vcftools using apt-get (stable)\n",
        "!apt-get update -qq\n",
        "!apt-get install -y samtools fastqc vcftools\n",
        "\n",
        "# Install cutadapt (requirement for Trim Galore, also installed via conda later)\n",
        "!pip install --quiet cutadapt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f6704e35"
      },
      "source": [
        "# Miniconda installation and environment setup for Colab NGS Workshop\n",
        "\n",
        "# Download and install Miniconda (skip if already installed)\n",
        "!wget -q https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh -O miniconda.sh\n",
        "!bash miniconda.sh -b -p /usr/local/miniconda\n",
        "\n",
        "import sys, os\n",
        "sys.path.append('/usr/local/miniconda/lib/python3.8/site-packages')\n",
        "os.environ['PATH'] = \"/usr/local/miniconda/bin:\" + os.environ['PATH']\n",
        "\n",
        "# Explicitly clear potentially problematic environment variables from Python's os.environ\n",
        "if 'CONDA_PREFIX' in os.environ:\n",
        "    del os.environ['CONDA_PREFIX']\n",
        "if 'CONDA_ENVS_PATH' in os.environ:\n",
        "    del os.environ['CONDA_ENVS_PATH']\n",
        "\n",
        "# Accept ToS for main and R conda channels\n",
        "!conda tos accept --override-channels --channel https://repo.anaconda.com/pkgs/main\n",
        "!conda tos accept --override-channels --channel https://repo.anaconda.com/pkgs/r\n",
        "\n",
        "# Create new conda environment for your workshop if it doesn't exist\n",
        "!if ! conda info --envs | grep -w 'workshop_ngs'; then \\\n",
        "    conda create -y -n workshop_ngs python=3.7; \\\n",
        "else \\\n",
        "    echo \"Environment 'workshop_ngs' already exists, skipping creation.\"; \\\n",
        "fi\n",
        "\n",
        "# Install necessary bioinformatics tools into the environment\n",
        "!conda install -y -n workshop_ngs -c bioconda -c conda-forge trim-galore samtools fastqc vcftools gatk4 bwa admixture plink\n",
        "\n",
        "# Verify tool versions inside activated environment in one shell session\n",
        "!bash -c \"source /usr/local/miniconda/bin/activate workshop_ngs && \\\n",
        "          trim_galore --version && samtools --version && fastqc --version && \\\n",
        "          vcftools --version && gatk --version && bwa && admixture --version && plink --version\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "70edf711"
      },
      "source": [
        "To activate the `workshop_ngs` environment for specific commands and ensure its tools are used, you can wrap your commands within a `bash -c \"source /usr/local/miniconda/bin/activate workshop_ngs && your_command_here\"` block. This ensures the environment is properly sourced before the command runs. Let's try listing the environment contents and checking `CONDA_PREFIX` within that activated session:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2f52e3b"
      },
      "source": [
        "!bash -c \"source /usr/local/miniconda/etc/profile.d/conda.sh && conda activate workshop_ngs && \\\n",
        "          echo '--- Environment activated ---' && \\\n",
        "          echo 'CONDA_PREFIX in activated env: '$CONDA_PREFIX && \\\n",
        "          echo '--- Listing contents of activated env ---' && \\\n",
        "          conda list\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5c5c06e3"
      },
      "source": [
        "Weâ€™ll be using real WGS resequencing data for this workshop. The dataset is a small subset for demonstration purposes. We will download the data from (https://zenodo.org/records/14258052) . Step 1 would be to make a parent directory to sort all the data in one place.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0a0fc21"
      },
      "source": [
        "!mkdir -p fastq_files\n",
        "!ls -F"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58d954b7"
      },
      "source": [
        "Now, let's navigate into the `fastq_files` directory."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fd7e272d"
      },
      "source": [
        "!cd fastq_files/ && pwd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8d6ca911"
      },
      "source": [
        "Let's organize the download process by first ensuring the `fastq_files` directory exists, then navigating into it to download all the FASTQ files directly to their intended location."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bb6bbeb7"
      },
      "source": [
        "# Define the list of FASTQ file links\n",
        "fastq_links = [\n",
        "    \"https://zenodo.org/records/14258052/files/BEN_CI16_sub_1.fq.gz\",\n",
        "    \"https://zenodo.org/records/14258052/files/BEN_CI16_sub_2.fq.gz\",\n",
        "    \"https://zenodo.org/records/14258052/files/BEN_CI18_sub_1.fq.gz\",\n",
        "    \"https://zenodo.org/records/14258052/files/BEN_CI18_sub_2.fq.gz\",\n",
        "    \"https://zenodo.org/records/14258052/files/BEN_NW10_sub_1.fq.gz\",\n",
        "    \"https://zenodo.org/records/14258052/files/BEN_NW10_sub_2.fq.gz\",\n",
        "    \"https://zenodo.org/records/14258052/files/BEN_NW12_sub_1.fq.gz\",\n",
        "    \"https://zenodo.org/records/14258052/files/BEN_NW12_sub_2.fq.gz\",\n",
        "    \"https://zenodo.org/records/14258052/files/BEN_NW13_sub_1.fq.gz\",\n",
        "    \"https://zenodo.org/records/14258052/files/BEN_NW13_sub_2.fq.gz\",\n",
        "    \"https://zenodo.org/records/14258052/files/BEN_SI18_sub_1.fq.gz\",\n",
        "    \"https://zenodo.org/records/14258052/files/BEN_SI18_sub_2.fq.gz\",\n",
        "    \"https://zenodo.org/records/14258052/files/BEN_SI19_sub_1.fq.gz\",\n",
        "    \"https://zenodo.org/records/14258052/files/BEN_SI19_sub_2.fq.gz\",\n",
        "    \"https://zenodo.org/records/14258052/files/BEN_SI9_sub_1.fq.gz\",\n",
        "    \"https://zenodo.org/records/14258052/files/BEN_SI9_sub_2.fq.gz\",\n",
        "    \"https://zenodo.org/records/14258052/files/LGS1_sub_1.fq.gz\",\n",
        "    \"https://zenodo.org/records/14258052/files/LGS1_sub_2.fq.gz\"\n",
        "]\n",
        "\n",
        "# Create the directory if it doesn't exist, and then download files into it\n",
        "!mkdir -p fastq_files\n",
        "\n",
        "\n",
        "# Remove any existing .fq.gz files to ensure a clean re-download\n",
        "!rm -f fastq_files/*.fq.gz\n",
        "\n",
        "# Change to the directory and download files\n",
        "# Using a subshell (bash -c) ensures the 'cd' command applies to the subsequent 'wget' commands\n",
        "for link in fastq_links:\n",
        "    !bash -c \"cd fastq_files && wget -P . -q {link}\"\n",
        "\n",
        "# List the contents of the fastq_files directory to confirm all downloads\n",
        "!ls -F fastq_files/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To visualise the content of the directory 'fastq_files' , to confirm that all the files have been successfully downloaded."
      ],
      "metadata": {
        "id": "NIKJbD1kB49q"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5e74bb29"
      },
      "source": [
        "Once all the fastq files are downloaded, the next would be to run \"FastQC\" tool on the raw reads for the quality assessment step before the downstream analysis part.\n",
        "\n",
        "***Why it's important:*** Poor-quality reads can lead to false variant calls or poor mapping, so quality control is crucial.\n",
        "\n",
        "To do so, first, let's create a directory to store the FastQC reports."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "93be3c96"
      },
      "source": [
        "!mkdir -p fastqc_results\n",
        "!ls -F"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1cf4153e"
      },
      "source": [
        "Now, we will run FastQC on all the FASTQ files within the `workshop_ngs` environment and save the reports to the `fastqc_results` directory."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddc193b1"
      },
      "source": [
        "%%time\n",
        "!bash -c \"source /usr/local/miniconda/etc/profile.d/conda.sh && conda activate workshop_ngs && \\\n",
        "          fastqc fastq_files/*.fq.gz -o fastqc_results\"\n",
        "\n",
        "# List the generated FastQC reports\n",
        "!ls -F fastqc_results/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The .html files generated by FastQC are standard web pages, which means you can visualize them by opening them in any web browser!\n",
        "\n",
        "Here's how you can access them from Colab:\n",
        " On the left-hand side of your Colab interface, there's usually a file explorer icon (a folder). Click on it to open the file browser. Navigate to the fastqc_results directory. You'll see all the .html files listed there. You can right-click on any .html file and select 'Download' to save it to your local machine, then open it with your preferred web browser.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "TLmb_MoTEJ-p"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "26726bab"
      },
      "source": [
        "Post qualitty assessment, the next step will be the trimming of the adapters or low-quality bases using tools such as Trim-galore. This step will ensure producing clean FASTQ files, ready for mapping.\n",
        "\n",
        "Step 1: We'll create a directory to store the trimmed FASTQ files."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "06e02af7"
      },
      "source": [
        "!mkdir -p trimmed_fastq_files\n",
        "!ls -F"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9bbe2bd9"
      },
      "source": [
        "Now, we will activate the `workshop_ngs` conda environment and run `Trim Galore!` on all the FASTQ files. We'll specify that they are paired-end reads and direct the output to the `trimmed_fastq_files` directory.\n",
        "\n",
        "Trim Galore automatically detects and removes common adapter sequences and performs quality trimming. The `--paired` option is essential for correctly processing paired-end reads."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3bd792c"
      },
      "source": [
        "%%time\n",
        "# Run Trim Galore! within the activated conda environment\n",
        "# We iterate through the samples to process paired-end reads correctly\n",
        "\n",
        "# Get a list of fastq files\n",
        "fastq_files_list = !ls fastq_files/*.fq.gz\n",
        "\n",
        "# Extract unique sample prefixes (e.g., BEN_CI16, BEN_CI18) from the filenames\n",
        "# We split by '/' to get just the filename, then split by '_sub_' to get the sample prefix\n",
        "sample_prefixes = sorted(list(set([f.split('/')[-1].split('_sub_')[0] for f in fastq_files_list])))\n",
        "\n",
        "for prefix in sample_prefixes:\n",
        "    read1 = f\"fastq_files/{prefix}_sub_1.fq.gz\"\n",
        "    read2 = f\"fastq_files/{prefix}_sub_2.fq.gz\"\n",
        "    output_dir = \"trimmed_fastq_files\"\n",
        "\n",
        "    # Use bash -c to activate conda env and run trim_galore\n",
        "    # --paired: for paired-end reads\n",
        "    # -o: specify output directory\n",
        "    # --fastqc: run FastQC on the trimmed output (optional but good for QC after trimming)\n",
        "    !bash -c \"source /usr/local/miniconda/etc/profile.d/conda.sh && conda activate workshop_ngs && \\\n",
        "              trim_galore --paired {read1} {read2} -o {output_dir} --fastqc\"\n",
        "\n",
        "# List the contents of the trimmed_fastq_files directory to confirm\n",
        "!ls -F trimmed_fastq_files/"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
